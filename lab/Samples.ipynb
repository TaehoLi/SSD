{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssd.vgg_ssd import create_vgg_ssd, create_vgg_ssd_predictor\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def image_print(image_path):\n",
    "    \n",
    "    net_type = \"vgg16-ssd\"\n",
    "    model_path = \"models/vgg16-ssd-Epoch-1-Loss-4.94469.pth\"\n",
    "    label_path = \"models/coco-model-labels.txt\"\n",
    "    data_dir = \"/home/user/hdd/coco/\"\n",
    "    config_name = \"vgg_ssd_config_300\"\n",
    "\n",
    "    class_names = [name.strip() for name in open(label_path).readlines()]\n",
    "    \n",
    "    if net_type == 'vgg16-ssd':\n",
    "        net = create_vgg_ssd(len(class_names), config_name, is_test=True)\n",
    "        predictor = create_vgg_ssd_predictor(net, config_name, candidate_size=200)\n",
    "    else:\n",
    "        print(\"The net type is wrong.\")\n",
    "    \n",
    "    try:\n",
    "        # original saved file with DataParallel\n",
    "        state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "        # create new OrderedDict that does not contain `module.`\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            name = k[7:] # remove `module.`\n",
    "            new_state_dict[name] = v\n",
    "        # load params\n",
    "        net.load_state_dict(new_state_dict)\n",
    "    except RuntimeError:\n",
    "        net.load(model_path)\n",
    "\n",
    "\n",
    "    #image_path = data_dir + \"images/val2014/\" + image_names_part[i] + \".jpg\"\n",
    "    print(\"Image name:\", image_path[7:32])\n",
    "\n",
    "    orig_image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n",
    "    boxes, labels, probs = predictor.predict(image, 10, 0.4)\n",
    "        \n",
    "    for i in range(boxes.size(0)):\n",
    "        box = boxes[i, :]\n",
    "        cv2.rectangle(orig_image, (box[0], box[1]), (box[2], box[3]), (0, 0, 255), 4)\n",
    "        label = str(class_names[labels[i]]) + \": \" + str(probs[i])[-7:-3]\n",
    "\n",
    "        cv2.putText(orig_image, label,\n",
    "                    (box[0] + 5, box[1] + 15),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,  # font scale\n",
    "                    (255,255,255),\n",
    "                    2)  # line type\n",
    "\n",
    "        \n",
    "    annotation_file = data_dir + \"annotations/instances_val2014.json\"\n",
    "    with open(annotation_file, encoding=\"utf-8\") as data_file:\n",
    "        data = json.load(data_file, object_pairs_hook=OrderedDict)\n",
    "\n",
    "    boxes = []\n",
    "    image_number = int(image_path[20:32])\n",
    "    \n",
    "    for index, name in enumerate(data[\"images\"]):\n",
    "        if name[\"id\"] == image_number:\n",
    "            image_height = name[\"height\"]\n",
    "            image_width = name[\"width\"]\n",
    "    for index, name in enumerate(data[\"annotations\"]):\n",
    "        category_id = name[\"category_id\"]\n",
    "        bbox = name[\"bbox\"]\n",
    "        if name[\"image_id\"] == image_number:\n",
    "            for index, name in enumerate(data[\"categories\"]):\n",
    "                if name[\"id\"] == category_id:\n",
    "\n",
    "                    xmin = round(bbox[0])\n",
    "                    if xmin == 0:\n",
    "                        xmin += 1\n",
    "                    ymin = round(bbox[1])\n",
    "                    if ymin == 0:\n",
    "                        ymin += 1\n",
    "                    xmax = round(bbox[0] + bbox[2])\n",
    "                    if xmax == image_width:\n",
    "                        xmax -= 1\n",
    "                    ymax = round(bbox[1] + bbox[3])\n",
    "                    if ymax == image_height:\n",
    "                        ymax -= 1\n",
    "\n",
    "                    bbox = [xmin, ymin, xmax, ymax]\n",
    "                    boxes.append(bbox)\n",
    "\n",
    "    for i, num in enumerate(boxes):\n",
    "        cv2.rectangle(orig_image, (boxes[i][0], boxes[i][1]), (boxes[i][2], boxes[i][3]), (0, 255, 0), 4)\n",
    "            \n",
    "    print(\"We find %d objects,\" %len(probs))\n",
    "    print(\"but actually there are %d objects.\" %len(boxes))\n",
    "        \n",
    "    img = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(9,9))\n",
    "    plt.axis('off')\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    path = \"run_ssd_example_output.jpg\"\n",
    "    ##cv2.imwrite(path, img)\n",
    "    \n",
    "\n",
    "image_print(\"./data/COCO_val2014_000000221291.jpg\")\n",
    "image_print(\"./data/COCO_val2014_000000245764.jpg\")\n",
    "image_print(\"./data/COCO_val2014_000000532481.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
